{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a26573",
   "metadata": {},
   "source": [
    "# Silksong Gesture Recognition - CNN/LSTM Training\n",
    "\n",
    "**Training for Hollow Knight: Silksong Voice-Controlled Watch Interface**\n",
    "\n",
    "This notebook trains a CNN/LSTM deep learning model for real-time gesture recognition.\n",
    "\n",
    "## Setup Requirements:\n",
    "1. ✅ Enable GPU: Runtime > Change runtime type > GPU (T4 recommended)\n",
    "2. ✅ Upload your data to Google Drive in: `My Drive/silksong_data/`\n",
    "3. ✅ Each session folder should contain:\n",
    "   - `sensor_data.csv` (accelerometer + gyroscope data)\n",
    "   - `[session]_labels.csv` (gesture labels with timestamps)\n",
    "\n",
    "## Expected Training Time:\n",
    "- **With GPU (T4):** 20-40 minutes\n",
    "- **Without GPU (CPU):** 2-4 hours (not recommended)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86407884",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aceaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✅ Google Drive mounted!\")\n",
    "print(\"Your data should be in: /content/drive/MyDrive/silksong_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f164440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"\\nGPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"\\n✅ GPU is enabled! Training will be fast.\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No GPU detected. Training will be slow.\")\n",
    "    print(\"   Enable GPU: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f205130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe216dd",
   "metadata": {},
   "source": [
    "## 2. Configure Data Paths\n",
    "\n",
    "**Update this cell with your session folder names!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c942800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory in Google Drive\n",
    "DATA_DIR = '/content/drive/MyDrive/silksong_data'\n",
    "\n",
    "# List your session folders here\n",
    "SESSION_FOLDERS = [\n",
    "    '20251017_125600_session',\n",
    "    '20251017_135458_session',\n",
    "    '20251017_141539_session',\n",
    "    '20251017_143217_session',\n",
    "    '20251017_143627_session',\n",
    "]\n",
    "\n",
    "# Model configuration\n",
    "# 🔧 REDUCED WINDOW SIZE to capture short gesture labels (0.3s duration)\n",
    "WINDOW_SIZE = 25  # 0.5 seconds at 50Hz (was 50 = 1.0s)\n",
    "STRIDE = 12       # 0.24 seconds overlap (was 25 = 0.5s)\n",
    "\n",
    "# Why reduced window size?\n",
    "# - Your voice labels are only 0.3s duration (word pronunciation time)\n",
    "# - Original 1.0s windows required 50 consecutive samples of same gesture\n",
    "# - 0.3s labels = 15 samples, can't fill a 50-sample window\n",
    "# - New 0.5s windows = 25 samples, can capture 0.3s labels!\n",
    "# - Expected result: 50-100 jump windows instead of only 7\n",
    "\n",
    "# Expected features: accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z,\n",
    "#                    rot_w, rot_x, rot_y, rot_z = 10 features\n",
    "# (timestamp and sensor columns are excluded)\n",
    "NUM_FEATURES = 10  # Will be verified during data loading\n",
    "\n",
    "# Gesture classes\n",
    "GESTURES = ['jump', 'punch', 'turn', 'walk', 'noise']\n",
    "NUM_CLASSES = len(GESTURES)\n",
    "\n",
    "print(f\"Configured {len(SESSION_FOLDERS)} sessions for training\")\n",
    "print(f\"Gestures: {GESTURES}\")\n",
    "print(f\"Window: {WINDOW_SIZE} samples ({WINDOW_SIZE/50.0:.2f}s) with {STRIDE} sample stride ({STRIDE/50.0:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb93add",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_session_data(session_folder):\n",
    "    \"\"\"Load sensor data and labels for one session\"\"\"\n",
    "    session_path = os.path.join(DATA_DIR, session_folder)\n",
    "\n",
    "    # Load sensor data\n",
    "    sensor_file = os.path.join(session_path, 'sensor_data.csv')\n",
    "    sensor_data_raw = pd.read_csv(sensor_file, skipinitialspace=True)\n",
    "\n",
    "    # Clean column names (strip whitespace)\n",
    "    sensor_data_raw.columns = sensor_data_raw.columns.str.strip()\n",
    "\n",
    "    # 🔧 FIX: Process sensor data to handle separate rows per sensor\n",
    "    # Sensor data has separate rows for each sensor type (linear_acceleration, gyroscope, rotation_vector)\n",
    "    # We need to merge them into one row per timestamp with all sensor values\n",
    "    \n",
    "    # Separate by sensor type\n",
    "    accel_data = sensor_data_raw[sensor_data_raw['sensor'] == 'linear_acceleration'][['timestamp', 'accel_x', 'accel_y', 'accel_z']].copy()\n",
    "    gyro_data = sensor_data_raw[sensor_data_raw['sensor'] == 'gyroscope'][['timestamp', 'gyro_x', 'gyro_y', 'gyro_z']].copy()\n",
    "    rot_data = sensor_data_raw[sensor_data_raw['sensor'] == 'rotation_vector'][['timestamp', 'rot_w', 'rot_x', 'rot_y', 'rot_z']].copy()\n",
    "    \n",
    "    # Get all unique timestamps\n",
    "    all_timestamps = pd.DataFrame({'timestamp': sorted(sensor_data_raw['timestamp'].unique())})\n",
    "    \n",
    "    # Merge all sensors on timestamp\n",
    "    sensor_data = all_timestamps.copy()\n",
    "    sensor_data = sensor_data.merge(accel_data, on='timestamp', how='left')\n",
    "    sensor_data = sensor_data.merge(gyro_data, on='timestamp', how='left')\n",
    "    sensor_data = sensor_data.merge(rot_data, on='timestamp', how='left')\n",
    "    \n",
    "    # Forward-fill to propagate sensor values (sensors update at different rates)\n",
    "    feature_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "    sensor_data[feature_cols] = sensor_data[feature_cols].ffill()\n",
    "    \n",
    "    # Fill any remaining NaN (at the beginning) with 0\n",
    "    sensor_data[feature_cols] = sensor_data[feature_cols].fillna(0)\n",
    "\n",
    "    # Load labels\n",
    "    labels_file = os.path.join(session_path, f'{session_folder}_labels.csv')\n",
    "    labels_data = pd.read_csv(labels_file)\n",
    "\n",
    "    return sensor_data, labels_data\n",
    "\n",
    "\n",
    "def create_label_vector(sensor_data, labels_data):\n",
    "    \"\"\"Create per-sample labels from segment labels\"\"\"\n",
    "    num_samples = len(sensor_data)\n",
    "    label_vector = np.full(num_samples, -1, dtype=int)\n",
    "\n",
    "    # Assuming 50Hz sampling rate\n",
    "    sample_rate = 50.0\n",
    "\n",
    "    for _, row in labels_data.iterrows():\n",
    "        start_time = row['timestamp']\n",
    "        duration = row['duration']\n",
    "        gesture = row['gesture']\n",
    "\n",
    "        if gesture not in GESTURES:\n",
    "            continue\n",
    "\n",
    "        gesture_idx = GESTURES.index(gesture)\n",
    "\n",
    "        # Convert time to sample indices\n",
    "        start_idx = int(start_time * sample_rate)\n",
    "        end_idx = int((start_time + duration) * sample_rate)\n",
    "\n",
    "        # Clip to valid range\n",
    "        start_idx = max(0, min(start_idx, num_samples))\n",
    "        end_idx = max(0, min(end_idx, num_samples))\n",
    "\n",
    "        label_vector[start_idx:end_idx] = gesture_idx\n",
    "\n",
    "    return label_vector\n",
    "\n",
    "\n",
    "def create_windows(sensor_data, labels, window_size, stride):\n",
    "    \"\"\"Create sliding windows from continuous data\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    num_samples = len(sensor_data)\n",
    "\n",
    "    for i in range(0, num_samples - window_size, stride):\n",
    "        window = sensor_data[i:i+window_size]\n",
    "        window_labels = labels[i:i+window_size]\n",
    "\n",
    "        # Skip if window contains unlabeled data\n",
    "        if np.any(window_labels == -1):\n",
    "            continue\n",
    "\n",
    "        # Use majority vote for window label\n",
    "        label = np.bincount(window_labels).argmax()\n",
    "\n",
    "        X.append(window)\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "print(\"✅ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process all sessions\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "for session_folder in SESSION_FOLDERS:\n",
    "    print(f\"\\nProcessing {session_folder}...\")\n",
    "\n",
    "    try:\n",
    "        sensor_data, labels_data = load_session_data(session_folder)\n",
    "        print(f\"  Sensor samples: {len(sensor_data)}\")\n",
    "        print(f\"  Label segments: {len(labels_data)}\")\n",
    "\n",
    "        # Extract features (exclude non-numeric columns: timestamp, sensor)\n",
    "        feature_cols = [col for col in sensor_data.columns\n",
    "                       if col not in ['timestamp', 'sensor']]\n",
    "\n",
    "        # Convert to float32 explicitly to avoid dtype issues\n",
    "        features = sensor_data[feature_cols].astype(np.float32).values\n",
    "\n",
    "        # Verify features are numeric\n",
    "        print(f\"  Feature columns ({len(feature_cols)}): {feature_cols}\")\n",
    "        print(f\"  Feature shape: {features.shape}\")\n",
    "        print(f\"  Feature dtype: {features.dtype}\")\n",
    "\n",
    "        # Create per-sample labels\n",
    "        label_vector = create_label_vector(sensor_data, labels_data)\n",
    "\n",
    "        # Create sliding windows\n",
    "        X, y = create_windows(features, label_vector, WINDOW_SIZE, STRIDE)\n",
    "        print(f\"  Generated {len(X)} windows\")\n",
    "\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "# Combine all sessions\n",
    "if all_X:\n",
    "    X_combined = np.concatenate(all_X, axis=0)\n",
    "    y_combined = np.concatenate(all_y, axis=0)\n",
    "\n",
    "    print(f\"\\n✅ Total training windows: {len(X_combined)}\")\n",
    "    print(f\"   Input shape: {X_combined.shape}\")\n",
    "    print(f\"   Labels shape: {y_combined.shape}\")\n",
    "    print(f\"   X dtype: {X_combined.dtype}\")\n",
    "    print(f\"   y dtype: {y_combined.dtype}\")\n",
    "\n",
    "    # Show class distribution\n",
    "    print(\"\\n   Class distribution:\")\n",
    "    for i, gesture in enumerate(GESTURES):\n",
    "        count = np.sum(y_combined == i)\n",
    "        percentage = count / len(y_combined) * 100\n",
    "        print(f\"     {gesture}: {count} ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"\\n❌ No data loaded! Check your data paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263dd63",
   "metadata": {},
   "source": [
    "## 4. Split Train/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "X_combined, y_combined = shuffle(X_combined, y_combined, random_state=42)\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_combined, y_combined, test_size=0.15, random_state=42, stratify=y_combined\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 of 0.85 ≈ 0.15 overall\n",
    ")\n",
    "\n",
    "print(f\"Training set:   {len(X_train)} samples ({len(X_train)/len(X_combined)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X_combined)*100:.1f}%)\")\n",
    "print(f\"Test set:       {len(X_test)} samples ({len(X_test)/len(X_combined)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 🔧 CHECK FOR NaN/INF IN DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nan_count = np.isnan(X_train).sum()\n",
    "inf_count = np.isinf(X_train).sum()\n",
    "\n",
    "print(f\"\\nNaN values in training data: {nan_count}\")\n",
    "print(f\"Inf values in training data: {inf_count}\")\n",
    "\n",
    "if nan_count > 0 or inf_count > 0:\n",
    "    print(\"⚠️  WARNING: Invalid values detected!\")\n",
    "    print(\"   Replacing NaN with 0 and clipping infinite values...\")\n",
    "    X_train = np.nan_to_num(X_train, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    X_val = np.nan_to_num(X_val, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    X_test = np.nan_to_num(X_test, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    print(\"✅ Data cleaned!\")\n",
    "\n",
    "# Check data range\n",
    "print(f\"\\nData range:\")\n",
    "print(f\"  Min: {X_train.min():.4f}\")\n",
    "print(f\"  Max: {X_train.max():.4f}\")\n",
    "print(f\"  Mean: {X_train.mean():.4f}\")\n",
    "print(f\"  Std: {X_train.std():.4f}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining set:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train == i)\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_val == i)\n",
    "    pct = count / len(y_val) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_test == i)\n",
    "    pct = count / len(y_test) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 🔧 SMART CLASS WEIGHT STRATEGY\n",
    "# ============================================================================\n",
    "# Use softened class weights to handle imbalance without numerical instability\n",
    "# Softening prevents extreme weights that can cause NaN loss\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS WEIGHT STRATEGY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "class_counts = [np.sum(y_train == i) for i in range(NUM_CLASSES)]\n",
    "max_class_count = max(class_counts)\n",
    "min_class_count = min(class_counts)\n",
    "imbalance_ratio = max_class_count / min_class_count\n",
    "\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.1f}x\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = class_counts[i]\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Compute balanced class weights\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# Apply softening: Use square root to reduce extreme weights\n",
    "# This prevents numerical instability while still helping minority classes\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"\\n🔧 Applying softening (sqrt) to prevent extreme weights...\")\n",
    "    class_weights_array = np.sqrt(class_weights_array)\n",
    "    class_weights = dict(enumerate(class_weights_array))\n",
    "    \n",
    "    print(\"\\nSoftened class weights:\")\n",
    "    for i, gesture in enumerate(GESTURES):\n",
    "        print(f\"  {gesture:8s}: {class_weights[i]:.3f}\")\n",
    "    \n",
    "    max_weight = max(class_weights.values())\n",
    "    min_weight = min(class_weights.values())\n",
    "    weight_ratio = max_weight / min_weight\n",
    "    print(f\"\\nWeight ratio after softening: {weight_ratio:.2f}x (was {imbalance_ratio:.1f}x)\")\n",
    "    print(\"✅ Softening reduces numerical instability while preserving class balance\")\n",
    "else:\n",
    "    print(\"\\n✅ Imbalance is moderate, using standard balanced weights\")\n",
    "    class_weights = dict(enumerate(class_weights_array))\n",
    "    \n",
    "    print(\"\\nClass weights:\")\n",
    "    for i, gesture in enumerate(GESTURES):\n",
    "        print(f\"  {gesture:8s}: {class_weights[i]:.3f}\")\n",
    "\n",
    "print(\"\\n💡 Expected results:\")\n",
    "print(\"   - All gestures: 75-85% accuracy (balanced learning)\")\n",
    "print(\"   - Overall: 85-92% accuracy\")\n",
    "print(\"   - Stable training with softened weights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73fe7c",
   "metadata": {},
   "source": [
    "## 5. Build CNN/LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7be364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(input_shape, num_classes):\n",
    "    \"\"\"Create CNN/LSTM architecture for gesture recognition\"\"\"\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "\n",
    "        # CNN layers for feature extraction\n",
    "        # Note: Adjusted for smaller window size (25 samples instead of 50)\n",
    "        layers.Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "        layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        # Removed second pooling to preserve temporal resolution with smaller input\n",
    "\n",
    "        # LSTM layers for temporal modeling\n",
    "        layers.LSTM(64, return_sequences=True),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Dense layers for classification\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create model\n",
    "input_shape = (WINDOW_SIZE, NUM_FEATURES)\n",
    "model = create_cnn_lstm_model(input_shape, NUM_CLASSES)\n",
    "\n",
    "# Compile model with GRADIENT CLIPPING to prevent NaN\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    clipnorm=1.0  # Clip gradients to prevent explosion\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print(f\"\\n💡 Model input shape: ({WINDOW_SIZE}, {NUM_FEATURES}) = {WINDOW_SIZE/50:.2f}s windows\")\n",
    "print(f\"   Optimizer: Adam with gradient clipping (clipnorm=1.0)\")\n",
    "print(f\"   This prevents NaN loss from exploding gradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7ff38",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"✅ Callbacks configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"🚀 Starting training...\\n\")\n",
    "\n",
    "# Choose your strategy:\n",
    "# OPTION 1: Use softened class weights (recommended for 400x imbalance)\n",
    "# OPTION 2: Set class_weights=None to train without weights\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,  # Using softened weights from previous cell\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba88d54",
   "metadata": {},
   "source": [
    "## 🔍 URGENT: Diagnose Training Issues\n",
    "\n",
    "**If you see training accuracy bouncing around 10-20% and validation accuracy dropping after epoch 3:**\n",
    "\n",
    "This suggests the class weights may be too extreme or there's a data issue. Run the diagnostic below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚨 CRITICAL DIAGNOSTIC: What went wrong?\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING ISSUE DIAGNOSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check what the model is actually predicting\n",
    "y_train_pred = model.predict(X_train[:500], verbose=0)  # Check first 500 samples\n",
    "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(\"\\n1️⃣ MODEL PREDICTION DISTRIBUTION (on training data):\")\n",
    "print(\"-\" * 70)\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train_pred_classes == i)\n",
    "    pct = count / len(y_train_pred_classes) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} predictions ({pct:5.1f}%)\")\n",
    "\n",
    "# Check if model is stuck predicting one class\n",
    "unique_preds = len(np.unique(y_train_pred_classes))\n",
    "print(f\"\\n  ⚠️  Model is predicting {unique_preds} out of {NUM_CLASSES} classes\")\n",
    "\n",
    "if unique_preds == 1:\n",
    "    print(f\"  🚨 PROBLEM: Model is ONLY predicting '{GESTURES[y_train_pred_classes[0]]}'!\")\n",
    "    print(\"  This means the model collapsed to always predict one class.\")\n",
    "\n",
    "# Check class weight values\n",
    "print(\"\\n2️⃣ CLASS WEIGHTS USED:\")\n",
    "print(\"-\" * 70)\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    print(f\"  {gesture:8s}: {class_weights[i]:.3f}\")\n",
    "\n",
    "max_weight = max(class_weights.values())\n",
    "min_weight = min(class_weights.values())\n",
    "weight_ratio = max_weight / min_weight\n",
    "\n",
    "print(f\"\\n  Weight ratio (max/min): {weight_ratio:.2f}x\")\n",
    "\n",
    "if weight_ratio > 10:\n",
    "    print(\"  ⚠️  EXTREME weight ratio! This can destabilize training.\")\n",
    "\n",
    "# Check actual class distribution again\n",
    "print(\"\\n3️⃣ ACTUAL CLASS DISTRIBUTION (training data):\")\n",
    "print(\"-\" * 70)\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train == i)\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Check for extreme imbalance\n",
    "class_counts = [np.sum(y_train == i) for i in range(NUM_CLASSES)]\n",
    "max_class_count = max(class_counts)\n",
    "min_class_count = min(class_counts)\n",
    "imbalance_ratio = max_class_count / min_class_count\n",
    "\n",
    "print(f\"\\n  Imbalance ratio (max/min): {imbalance_ratio:.2f}x\")\n",
    "\n",
    "if imbalance_ratio > 30:\n",
    "    print(\"  🚨 SEVERE IMBALANCE! The rarest class has <3% of data.\")\n",
    "    print(\"  Recommendation: Collect more data for rare classes.\")\n",
    "elif imbalance_ratio > 10:\n",
    "    print(\"  ⚠️  SIGNIFICANT IMBALANCE. Class weights may need adjustment.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if weight_ratio > 10:\n",
    "    print(\"\\n✅ FIX #1: Use Softer Class Weights\")\n",
    "    print(\"   Replace the class weight calculation with:\")\n",
    "    print(\"   ```\")\n",
    "    print(\"   # Softer class weights (less extreme)\")\n",
    "    print(\"   class_weights_array = compute_class_weight(\")\n",
    "    print(\"       'balanced', classes=np.unique(y_train), y=y_train\")\n",
    "    print(\"   )\")\n",
    "    print(\"   # Apply square root to soften weights\")\n",
    "    print(\"   class_weights_array = np.sqrt(class_weights_array)\")\n",
    "    print(\"   class_weights = dict(enumerate(class_weights_array))\")\n",
    "    print(\"   ```\")\n",
    "\n",
    "if imbalance_ratio > 20:\n",
    "    print(\"\\n✅ FIX #2: Try Training Without Class Weights First\")\n",
    "    print(\"   The imbalance might not be as bad as it looks.\")\n",
    "    print(\"   Comment out the class_weight parameter:\")\n",
    "    print(\"   ```\")\n",
    "    print(\"   history = model.fit(\")\n",
    "    print(\"       X_train, y_train,\")\n",
    "    print(\"       validation_data=(X_val, y_val),\")\n",
    "    print(\"       # class_weight=class_weights,  # Try without this\")\n",
    "    print(\"       epochs=100,\")\n",
    "    print(\"       ...\")\n",
    "    print(\"   ```\")\n",
    "\n",
    "print(\"\\n✅ FIX #3: Check Your Data Quality\")\n",
    "print(\"   Run the evaluation cells below to see the confusion matrix.\")\n",
    "print(\"   If the model saved at epoch 3 actually works, you might be fine!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b090c",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Train')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Train')\n",
    "ax2.plot(history.history['val_loss'], label='Validation')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n📊 Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_classes, target_names=GESTURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f97707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=GESTURES, yticklabels=GESTURES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Normalized)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b478209",
   "metadata": {},
   "source": [
    "## 8. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Google Drive\n",
    "model_save_path = '/content/drive/MyDrive/silksong_data/cnn_lstm_gesture.h5'\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(f\"✅ Model saved to: {model_save_path}\")\n",
    "print(\"\\nDownload this file to your local project and place it in the 'models/' directory\")\n",
    "print(\"Then run: python src/udp_listener_v3.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e889e1",
   "metadata": {},
   "source": [
    "## ✅ Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Download the trained model:**\n",
    "   - Right-click on the file in Google Drive: `silksong_data/cnn_lstm_gesture.h5`\n",
    "   - Download to your local machine\n",
    "\n",
    "2. **Place model in your project:**\n",
    "   ```bash\n",
    "   # Move to your project's models directory\n",
    "   mv ~/Downloads/cnn_lstm_gesture.h5 /path/to/project/models/\n",
    "   ```\n",
    "\n",
    "3. **Test real-time recognition:**\n",
    "   ```bash\n",
    "   cd src\n",
    "   python udp_listener_v3.py\n",
    "   ```\n",
    "\n",
    "4. **Expected performance:**\n",
    "   - Latency: 10-30ms per prediction\n",
    "   - Accuracy: 90-98%\n",
    "   - Much faster than Phase IV SVM model!\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Check the documentation in `docs/Phase_V/README.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
